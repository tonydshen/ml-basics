{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/034adarsh/Stock-Price-Prediction-Using-LSTM/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yrU0iWdalVGx",
      "metadata": {
        "id": "yrU0iWdalVGx"
      },
      "source": [
        "# Import all the required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4189cf86",
      "metadata": {
        "id": "4189cf86",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from pandas_datareader import data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import urllib.request, json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e848f4bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the stock ticker and date ranges\n",
        "ticker='QUBT'\n",
        "start_date='2010-01-01'\n",
        "end_date='2025-07-31'\n",
        "training_data_start_date='2010-01-01'\n",
        "training_data_end_date='2022-12-31'\n",
        "validation_data_start_date='2023-01-01'\n",
        "validation_data_end_date='2023-12-31'\n",
        "test_data_start_date='2024-01-01'\n",
        "test_data_end_date='2024-12-31'\n",
        "prediction_start_date='2025-01-01'\n",
        "# Download historical data for a stock from Yahoo Finance\n",
        "df = yf.download(ticker, start=start_date, end=end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06bf8833",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort DataFrame by date\n",
        "df = df.sort_values('Date')\n",
        "\n",
        "# Double check the result\n",
        "df.head()\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad8ea50",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),(df['Low']+df['High'])/2.0)\n",
        "plt.xticks(range(0,df.shape[0],500),df['Date'].loc[::500],rotation=45)\n",
        "plt.xlabel('Date',fontsize=18)\n",
        "plt.ylabel('Mid Price',fontsize=18)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b369838f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# First calculate the mid prices from the highest and lowest\n",
        "high_prices = df.loc[:,'High'].as_matrix()\n",
        "low_prices = df.loc[:,'Low'].as_matrix()\n",
        "mid_prices = (high_prices+low_prices)/2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c840712d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# train and test split\n",
        "train_data = mid_prices[:11000]\n",
        "test_data = mid_prices[11000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42efe2be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale the data to be between 0 and 1\n",
        "# When scaling remember! You normalize both test and train data with respect to training data\n",
        "# Because you are not supposed to have access to test data\n",
        "scaler = MinMaxScaler()\n",
        "train_data = train_data.reshape(-1,1)\n",
        "test_data = test_data.reshape(-1,1)\n",
        "smoothing_window_size = 2500\n",
        "# We smooth the data and also scale it by gpt-4\n",
        "for di in range(0,10000,smoothing_window_size):\n",
        "    scaler.fit(train_data[di:di+smoothing_window_size,:])\n",
        "    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\n",
        "scaler.fit(train_data[di+smoothing_window_size:,:])\n",
        "train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])\n",
        "test_data = scaler.transform(test_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
